# Ember cli-deploy

## Installing

- ember-cli-dotenv: allows to externalize variables to a .env file that is not committed to source code
- ember-cli-deploy: a wrapper around other plugins that actually do the work, e.g. S3
- ember-cli-deploy-build: repsonsible for packaging everything up for deployment
- ember-cli-deploy-s3: deploy the build bundle to AWS S3
- ember-cli-deploy-revision-data: generates a unique revision key for each deployment which is used by other plugins
- ember-cli-deploy-display-revisions: modifies the deploy list command to show deploy revisions
- ember-cli-deploy-s3-index: this allows ember deploy to fetch revisions from S3

```bash
ember install ember-cli-dotenv
ember install ember-cli-deploy
ember install ember-cli-deploy-build
ember install ember-cli-deploy-s3
ember install ember-cli-deploy-revision-data
ember install ember-cli-deploy-display-revisions
ember install ember-cli-deploy-s3-index
```

Installing ember-cli-deploy creates config/deploy.js


## Create S3 bucket for deployment

- Documented here: https://github.com/ember-cli-deploy/ember-cli-deploy-s3#minimum-s3-permissions
- Permissions need to be set on the bucket (this is done automatically via Terraform)
- Note that the bucket-name in the permissions file needs to match the value of `ember_app_bucket` (this is also done automatically via Terraform)
- The bucket name is defined in a Terraform var (currently as `ember_app_bucket`)


## Configure deployment

### Place AWS Credentials in config/deploy.js

- Documented here: https://github.com/ember-cli-deploy/ember-cli-deploy-s3#quick-start
- Terraform writes the credentials to /tmp/s3_bucket_credentials.yml
- Manually copy the values from that file to inventory/group_vars/all/vault
- run recheck-development.yml to write out the env file

### config/deploy.js

This has settings for multiple environments. Make changes here to configure the deployment

```js
module.exports = function(deployTarget) {
  var ENV = {
    build: {}
    s3: {
      accessKeyId: process.env.AWS_ACCESS_KEY_ID,
      secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY,
      bucket: process.env.AWS_BUCKET,
      region: process.env.AWS_REGION,
    }
  };
```


## Deploy

- Package everything in project_root/dists which is then ready to be deployed

```bash
ember build deploy
```

- Is the next step necessary? What does it do?

```bash
ember deploy build
```

- Deploy to staging

```bash
ember deploy staging
```

OR invoke alias:

```bash
ebds
```

ember build deploy; ember deploy staging

ember deploy:list staging

## Access the application

http://recheck.staging.rhodesedge.com


## NOTEs

Because Ember is always deployed from the same server (development) the env strategy used for server deployment where the environment
is set with tags on an ELB or in ansible hosts to yield a single env file with the correct envs for the particular environment

Therefore in Ember's config/deploy.js and config/environment.js the env vars are postfixed with the environment, e.g. AWS_REGION_PRODUCTION
For local development we can go with localhost hardcoded. For staging and production those values come from the env file which in turn
is generated by ansible from a source file created by Terraform

TF is where Route53 is setup so the domain name should come from there (keeping it DRY)

### DNS

- each environment has it's own VPC and sub-domain, e.g. staging
- the application is served from an S3 bucket which responds to application.environment.domain
- the API server is behind an ELB which is mapped to application-api.environment.domain
- CORS also needs to be setup in Rails that allows recheck.staging.rhodesedge.com
